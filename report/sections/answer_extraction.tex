After the passage retrieval a list of paragraphs is retrieved where the answer is likely exists. 
From these pieces of text the goal is to rank all the words and hopefully the right one comes out on top.
The system only focuses on nouns and proper nouns.

\subsection{Rank nouns}

The passages/paragraphs retrieved with help of Lucene is assumed to frequently contain the right answer
because found paragraphs should be closely related to the question.

The nouns and proper nouns are extracted from all found paragraphs with the help of a Part of Speech (PoS) 
tagger, in our case Stagger \cite{stagger}.

From the obtained list of passages scores for how well every paragraph fits our question, i.e the bm25 score. 
This is used together with the number of occurances of a noun to calculate the rank.
More precisely: For each noun that is found in any of the paragraphs the rank is calculated as in the formula (\ref{eq:nounrank}).

\begin{equation}
nounrank = \sum_{p\:\in\:paragraphs}bm25(p) \cdot c_p
\label{eq:nounrank}
\end{equation}

where bm25(p) is the bm25 score of a paragraph and c is the number of occurances of the word in a paragraph

\subsection{Reranker}

Reranking the nouns further is done using machine learning and more specifically logistic regression.
A model is trained with our training set and then used to predict the best answer candidate from a question.

When training the model, three feature vectors and a true/false value is used. 
The features vectors used is question words, answer words and question (predicted) categories, and the true/false
value determines if the answer matches the actual answer.

To predict the probability for each of the ranked nouns to be the right answer, the question words and predicted categories
is used together with each ranked noun. The resulting probability is then weighted together with the noun rank to get the
reranked score (\ref{eq:rerank}). Finally the score is normalized to get an easier overview of the results.

\begin{equation}
rerank = \sqrt{n} \cdot p^2
\label{eq:rerank}
\end{equation}

where n is the nounrank (\ref{eq:nounrank}) and p is the probability that the tested answer is correct according 
to the trained model.

\subsection{Puncher}

To further improve the ranking we have experimented with a module we call the puncher. It simply boosts 
words with a matching category (stagger) to the predicted categories (libshorttext). 